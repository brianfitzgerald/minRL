{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30350625",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fb51ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from minrl.algorithms import (\n",
    "    rollout\n",
    ")\n",
    "from minrl.tasks.connections import ConnectionsDataset, connections_reward_func\n",
    "from minrl.constants import GEMMA_3_1B\n",
    "from transformers import AutoTokenizer\n",
    "from vllm import LLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(GEMMA_3_1B)\n",
    "\n",
    "\n",
    "dataset = ConnectionsDataset(split=\"eval\", host=\"notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b760d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "vllm_model = LLM(\n",
    "    model=GEMMA_3_1B,\n",
    "    gpu_memory_utilization=0.5,\n",
    "    max_model_len=1024,\n",
    "    max_seq_len_to_capture=1024,\n",
    "    enforce_eager=True,\n",
    "    enable_prefix_caching=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360e7d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "model = AutoModelForCausalLM.from_pretrained(GEMMA_3_1B, device_map=\"auto\", dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8021e56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4961436a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = dataset[:4]\n",
    "\n",
    "conversations = [\n",
    "    dataset.initial_conversation(sample, i)\n",
    "    for i, sample in enumerate(batch)\n",
    "]\n",
    "\n",
    "episodes = rollout(\n",
    "    1,\n",
    "    512,\n",
    "    tokenizer,\n",
    "    4,\n",
    "    1,\n",
    "    conversations,\n",
    "    batch,\n",
    "    reward_function=connections_reward_func,\n",
    "    vllm_model=vllm_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6af91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from minrl.algorithms import process_batch\n",
    "from minrl.trainer import get_available_device\n",
    "\n",
    "# Process the batch\n",
    "logprobs, target_masks, batch_rewards_t, batch_entropy, n_target_tokens = (\n",
    "    process_batch(\n",
    "        model=model,\n",
    "        episodes=episodes,\n",
    "        tokenizer=tokenizer,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        device=torch.device(\"cuda\"),\n",
    "    )\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
