{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_LAUNCH_BLOCKING=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brianfitzgerald/Documents/GitHub/minRL/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%env CUDA_LAUNCH_BLOCKING=1\n",
    "import torch\n",
    "\n",
    "from main import init_model, init_training, create_connections_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-04 19:48:36.360\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmain\u001b[0m:\u001b[36minit_model\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mModel loaded.\u001b[0m\n",
      "\u001b[32m2025-05-04 19:48:36.362\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmain\u001b[0m:\u001b[36minit_model\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mUsing device mps\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "tokenizer, model = init_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, _ = create_connections_datasets(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_objects = init_training(model, train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-04 19:58:56.285\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgrpo\u001b[0m:\u001b[36mrollout\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mGenerating responses for 1 prompts, max_gen_len=100\u001b[0m\n",
      "\u001b[32m2025-05-04 19:59:02.159\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgrpo\u001b[0m:\u001b[36mrollout\u001b[0m:\u001b[36m73\u001b[0m - \u001b[1mGenerated token ids: 100\u001b[0m\n",
      "\u001b[32m2025-05-04 19:59:02.159\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgrpo\u001b[0m:\u001b[36mrollout\u001b[0m:\u001b[36m80\u001b[0m - \u001b[1mGenerated token ids after removing padding: 100\u001b[0m\n",
      "\u001b[32m2025-05-04 19:59:02.160\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgrpo\u001b[0m:\u001b[36mrollout\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mGenerated text: \n",
      "\n",
      "Okay, let's see. The user provided a list of words: file, history, view, window, asteroids, breakout, frogger, pong, dip, drop, fall, sink, advance, march, progress, push. I need to form four groups of four words each, with each word used only once. Let me start by looking for obvious categories.\n",
      "\n",
      "First, \"file,\" \"view,\" \"window,\" and \"history\" seem related to a digital environment.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards {'reward': 0.0, 'reward_info': {'format_reward': 0.0, 'answer_reward': 0.0}}\n"
     ]
    }
   ],
   "source": [
    "from main import init_training\n",
    "from grpo import rollout, update_policy\n",
    "\n",
    "from tasks.countdown import reward_function\n",
    "\n",
    "to = init_training(model, train_dataset)\n",
    "batch = next(iter(to.train_dataloader))\n",
    "\n",
    "episodes = rollout(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    batch=batch,\n",
    "    max_gen_len=to.config.max_gen_len,\n",
    "    num_answer_per_question=to.config.num_answer_per_question,\n",
    "    reward_function=reward_function,\n",
    "    device=to.device,\n",
    ")\n",
    "if to.config.skip_unfinished_episodes:\n",
    "    episodes = [episode for episode in episodes if episode.is_finished]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CausalLMOutputWithPast(loss=None, logits=tensor([[[ 5.6875,  4.7188,  3.5781,  ...,  1.3750,  1.3750,  1.3750],\n",
       "         [10.5000,  0.7227,  0.2070,  ..., -1.7109, -1.7109, -1.7109],\n",
       "         [15.3125,  7.5938,  5.4375,  ..., -1.8984, -1.8984, -1.8984],\n",
       "         [ 6.3125,  3.8125,  4.1562,  ...,  0.0510,  0.0510,  0.0510]]],\n",
       "       device='mps:0', dtype=torch.bfloat16, grad_fn=<LinearBackward0>), past_key_values=<transformers.cache_utils.DynamicCache object at 0x147a3cb60>, hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(input.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-04 19:58:49.470\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgrpo\u001b[0m:\u001b[36mupdate_policy\u001b[0m:\u001b[36m8\u001b[0m - \u001b[1mUpdating policy with 1 episodes, 100 target tokens, 1 micro-batches\u001b[0m\n",
      "* Computing policy gradient:  0/ 1\u001b[0mmINFO    \u001b[0m | \u001b[36mgrpo\u001b[0m:\u001b[36mupdate_policy\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episodes [0.0]\n",
      "rewards tensor([0.], device='mps:0')\n",
      "mean tensor(0., device='mps:0')\n",
      "std 0\n",
      "batch ep [0.0]\n"
     ]
    }
   ],
   "source": [
    "# Update policy - compute loss and perform backward pass\n",
    "results = update_policy(\n",
    "    model=model,\n",
    "    optimizer=to.optimizer,\n",
    "    episodes=episodes,\n",
    "    micro_batch_size=to.config.micro_batch_size,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    max_grad_norm=to.config.max_grad_norm,\n",
    "    device=to.device,\n",
    "    dtype=to.dtype,\n",
    "    apply_loss=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
