{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_LAUNCH_BLOCKING=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brianfitzgerald/Documents/GitHub/minRL/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%env CUDA_LAUNCH_BLOCKING=1\n",
    "import torch\n",
    "\n",
    "from main import init_model, init_training, create_connections_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-05 20:57:57.588\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmain\u001b[0m:\u001b[36minit_model\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mModel loaded.\u001b[0m\n",
      "\u001b[32m2025-05-05 20:57:57.590\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmain\u001b[0m:\u001b[36minit_model\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mUsing device mps\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "tokenizer, model = init_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, _ = create_connections_datasets(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_objects = init_training(model, train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-05 21:29:51.909\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgrpo\u001b[0m:\u001b[36mrollout\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mGenerating responses for 1 prompts, max_tokens=512\u001b[0m\n",
      "\u001b[32m2025-05-05 21:30:15.314\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgrpo\u001b[0m:\u001b[36mrollout\u001b[0m:\u001b[36m73\u001b[0m - \u001b[1mGenerated token ids: 387\u001b[0m\n",
      "\u001b[32m2025-05-05 21:30:15.315\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgrpo\u001b[0m:\u001b[36mrollout\u001b[0m:\u001b[36m80\u001b[0m - \u001b[1mGenerated token ids after removing padding: 387\u001b[0m\n",
      "\u001b[32m2025-05-05 21:30:15.316\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgrpo\u001b[0m:\u001b[36mrollout\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mGenerated text: \n",
      "\n",
      "Okay, let's see. The user provided a list of words: copy, text, words, writing, agent, asset, mole, sleeper, choice, say, voice, vote, fiat, jaguar, mini. They want me to group them into four groups of four, each related to each other. Each word can only be in one group.\n",
      "\n",
      "First, I need to look for obvious connections. Let's start with \"copy, text, words, writing\". These all seem related to writing. Copy can mean to copy text, text is part of writing, words are the elements of writing, and writing is the activity. So that's a group: copy, text, words, writing.\n",
      "\n",
      "Next, \"agent, asset, mole, sleeper\". Agent is involved in an asset, asset can be a mole or a sleeper. Agent and sleeper are related to agents and their roles. So that's another group: agent, asset, mole, sleeper.\n",
      "\n",
      "Now, the remaining words are choice, say, voice, vote. These all relate to communication or speech. Choice and say are synonyms. Voice and vote are related to communication. So that's the last group: choice, say, voice, vote.\n",
      "\n",
      "Wait, let me check again. Agent, asset, mole, sleeper. Agent and asset are related, mole and sleeper are roles. Check. Copy, text, words, writing. All about writing. Choice, say, voice, vote. All about communication. That seems to fit. Each group has four words, no overlaps. So the answer should be the four groups as above.\n",
      "</think>\n",
      "\n",
      "<reasoning>\n",
      "Group 1: copy, text, words, writing  \n",
      "Group 2: agent, asset, mole, sleeper  \n",
      "Group 3: choice, say, voice, vote  \n",
      "Group 4: jaguar, mini, ram, fiat  \n",
      "</reasoning>\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards {'reward': 0.010000000000000002, 'reward_info': {'format_reward': 0.1, 'answer_reward': 0.0}}\n"
     ]
    }
   ],
   "source": [
    "from main import init_training\n",
    "from grpo import rollout, update_policy\n",
    "\n",
    "from tasks.countdown import reward_function\n",
    "\n",
    "to = init_training(model, train_dataset)\n",
    "batch = next(iter(to.train_dataloader))\n",
    "\n",
    "episodes = rollout(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    batch=batch,\n",
    "    max_new_tokens=to.config.max_new_tokens,\n",
    "    num_answer_per_question=to.config.num_answer_per_question,\n",
    "    reward_function=reward_function,\n",
    "    device=to.device,\n",
    ")\n",
    "if to.config.skip_unfinished_episodes:\n",
    "    episodes = [episode for episode in episodes if episode.is_finished]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010000000000000002"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "episodes[0].reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-05 21:30:56.136\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgrpo\u001b[0m:\u001b[36mupdate_policy\u001b[0m:\u001b[36m180\u001b[0m - \u001b[1mUpdating policy with 1 episodes, 387 target tokens, 1 micro-batches\u001b[0m\n",
      "* Computing policy gradient:  0/ 1\u001b[0mmINFO    \u001b[0m | \u001b[36mgrpo\u001b[0m:\u001b[36mupdate_policy\u001b[0m:\u001b[36m187\u001b[0m - \u001b[1m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episodes [0.010000000000000002]\n",
      "rewards tensor([0.0100], device='mps:0')\n",
      "mean tensor(0.0100, device='mps:0')\n",
      "std 0\n",
      "batch ep [0.0]\n"
     ]
    }
   ],
   "source": [
    "# Update policy - compute loss and perform backward pass\n",
    "results = update_policy(\n",
    "    model=model,\n",
    "    optimizer=to.optimizer,\n",
    "    episodes=episodes,\n",
    "    micro_batch_size=to.config.micro_batch_size,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    max_grad_norm=to.config.max_grad_norm,\n",
    "    device=to.device,\n",
    "    dtype=to.dtype,\n",
    "    apply_loss=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': -0.0, 'grad_norm': 0.0, 'entropy': 1.5390625}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
