{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%env CUDA_LAUNCH_BLOCKING=1\n",
    "import torch\n",
    "\n",
    "from train import init_model, init_training, create_connections_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-06 21:15:47.835\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrain\u001b[0m:\u001b[36minit_model\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1mModel loaded.\u001b[0m\n",
      "\u001b[32m2025-05-06 21:15:47.842\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtrain\u001b[0m:\u001b[36minit_model\u001b[0m:\u001b[36m7\u001b[0m - \u001b[1mUsing device cuda:0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "tokenizer, model = init_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, _ = create_connections_datasets(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_objects = init_training(model, train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-06 21:16:38.984\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgrpo\u001b[0m:\u001b[36mrollout\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mGenerating responses for 2 prompts, max_tokens=256\u001b[0m\n",
      "\u001b[32m2025-05-06 21:17:35.359\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgrpo\u001b[0m:\u001b[36mrollout\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mGenerated token ids: 256\u001b[0m\n",
      "\u001b[32m2025-05-06 21:17:35.361\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgrpo\u001b[0m:\u001b[36mrollout\u001b[0m:\u001b[36m81\u001b[0m - \u001b[1mGenerated token ids after removing padding: 256\u001b[0m\n",
      "\u001b[32m2025-05-06 21:17:35.362\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgrpo\u001b[0m:\u001b[36mrollout\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mGenerated text: \n",
      "\n",
      "Okay, let's see. The user provided a list of words and wants me to group them into four groups of four, each related. Each word can only be in one group. Let me start by looking at the words.\n",
      "\n",
      "First, the words are: caw, chirp, cluck, tweet, bunk, crock, hogwash, horsefeathers, fruit, pitcher, skull, tablecloth, contact, message, ping, text.\n",
      "\n",
      "Hmm, some of these sounds like animals. Caw, chirp, cluck, tweet, cluck... Wait, cluck is a common animal sound. Also, cricket, cricket... but the words here are \"horsefeathers\". Wait, \"horsefeathers\" is a term for horse feathers, but maybe not directly related. Let me think.\n",
      "\n",
      "Another angle: \"bunk\" and \"pitcher\" are related to something in a container. \"Crock\" is a container. \"Tablecloth\" and \"contact\" and \"message\" and \"text\" could be related to communication or messages. Let me try grouping.\n",
      "\n",
      "Group 1: Caw, chirp, cluck, tweet. These are all animal sounds. That's four words. Good.\n",
      "\n",
      "Group \u001b[0m\n",
      "\u001b[32m2025-05-06 21:17:35.363\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgrpo\u001b[0m:\u001b[36mrollout\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mGenerated token ids: 256\u001b[0m\n",
      "\u001b[32m2025-05-06 21:17:35.364\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgrpo\u001b[0m:\u001b[36mrollout\u001b[0m:\u001b[36m81\u001b[0m - \u001b[1mGenerated token ids after removing padding: 256\u001b[0m\n",
      "\u001b[32m2025-05-06 21:17:35.365\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgrpo\u001b[0m:\u001b[36mrollout\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mGenerated text: \n",
      "\n",
      "Okay, let's see. The user provided a list of words: caw, chirp, cluck, tweet, bunk, crock, hogwash, horsefeathers, fruit, pitcher, skull, tablecloth, contact, message, ping, text. They want me to group them into four groups of four words each, each related to each other. \n",
      "\n",
      "First, I need to look for common themes or categories. Let's start with the first group. Words like \"caw, chirp, cluck, tweet\" all seem to be types of sounds. These are all bird sounds, so that's a good start. So group 1 could be caw, chirp, cluck, tweet.\n",
      "\n",
      "Next, \"bunk, crock, hogwash, message\" – bunk is a place to sleep, crock is a container, hogwash is something that's not useful, and message is a message. Maybe they are related to things to sleep or messages? Not sure yet. But \"bunk\" and \"message\" could be separate. Let's check another group. \"Pitcher, tablecloth, contact, text\" – pitcher is a container, tablecloth is a cloth, contact is a physical contact\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards {'reward': 0.0, 'reward_info': {'format_reward': 0.0, 'answer_reward': 0.0}}\n",
      "rewards {'reward': 0.0, 'reward_info': {'format_reward': 0.0, 'answer_reward': 0.0}}\n"
     ]
    }
   ],
   "source": [
    "from train import init_training\n",
    "from grpo import rollout, update_policy\n",
    "\n",
    "from tasks.countdown import reward_function\n",
    "\n",
    "to = init_training(model, train_dataset)\n",
    "batch = next(iter(to.train_dataloader))\n",
    "\n",
    "episodes = rollout(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    batch=batch,\n",
    "    max_new_tokens=to.config.max_new_tokens,\n",
    "    num_answer_per_question=to.config.num_answer_per_question,\n",
    "    reward_function=reward_function,\n",
    "    device=to.device,\n",
    ")\n",
    "if to.config.skip_unfinished_episodes:\n",
    "    episodes = [episode for episode in episodes if episode.is_finished]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes[0].reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update policy - compute loss and perform backward pass\n",
    "results = update_policy(\n",
    "    model=model,\n",
    "    optimizer=to.optimizer,\n",
    "    episodes=episodes,\n",
    "    micro_batch_size=to.config.micro_batch_size,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    max_grad_norm=to.config.max_grad_norm,\n",
    "    device=to.device,\n",
    "    dtype=to.dtype,\n",
    "    apply_loss=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
